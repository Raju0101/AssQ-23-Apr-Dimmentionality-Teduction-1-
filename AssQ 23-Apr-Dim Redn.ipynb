{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc2ab94a-0452-4cf3-9c12-9fe2c4ac386a",
   "metadata": {},
   "source": [
    "# AssQ 23-Apr- Dimentionality Reduction-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09c98fb-925c-4ecd-b33b-0d8c1e8dfbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. What is the curse of dimensionality reduction and why is it important in machine learning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7d0f34-5f88-46d2-8936-4413f6454ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "The curse of dimensionality basically refers to the difficulties a machine learning algorithm faces \n",
    "when working with data in the higher dimensions, that did not exist in the lower dimensions.\n",
    "This happens because when you add dimensions (features), the minimum data requirements also increase rapidly.\n",
    "\n",
    "As the dimensionality increases, the number of data points required for good performance of any machine learning algorithm increases exponentially. \n",
    "The reason is that, we would need more number of data points for any given combination of features, for any machine learning model to be valid.\n",
    "\n",
    "The curse of dimensionality basically means that the error increases with the increase in the number of features.\n",
    "It refers to the fact that algorithms are harder to design in high dimensions and often have a running time exponential in the dimensions.\n",
    "\n",
    "The curse of dimensionality refers to a set of problems that arise when working with high-dimensional data.\n",
    "The dimension of a dataset corresponds to the number of attributes or features that exist in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef3cb07-7af1-4744-8111-badf1b1adeb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089e64cb-d999-4dbe-8118-06d52f398905",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. How does the curse of dimensionality impact the performance of machine learning algorithms?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6960e398-3d5e-4107-b4a0-f7d5807c31c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "As the dimensionality increases, the number of data points required for good performance\n",
    "of any machine learning algorithm increases exponentially. The reason is that,\n",
    "we would need more number of data points for any given combination of features,\n",
    "for any machine learning model to be valid.\n",
    "\n",
    "\n",
    "Curse of Dimensionality describes the explosive nature of increasing data dimensions\n",
    "and its resulting exponential increase in computational efforts required for its processing and/or analysis.\n",
    "\n",
    "It's harder to catch a dog if it were running around on the plane (two dimensions).\n",
    "It's much harder to hunt birds, which now have an extra dimension they can move in. \n",
    "If we pretend that ghosts are higher-dimensional beings, those are even more difficult to catch.\n",
    "\n",
    "As the dimensionality increases, the distance between objects may be heavily dominated by noise. \n",
    "That is, the distance and similarity between two points in a high-dimensional space may not reflect the real relationship between the points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5928a7dd-c1a4-43e0-812e-911622974be1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0034fb-bedb-4695-bb81-351eaa4a67ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. What are some of the consequences of the curse of dimensionality in machine learning, and how do\n",
    "they impact model performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4829ba-4db1-430b-a7d1-74f5937ab3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "As the number of dimensions or features increases, the amount of data needed to generalize the machine\n",
    "learning model accurately increases exponentially.\n",
    "The increase in dimensions makes the data sparse, and it increases the difficulty of generalizing the model.\n",
    "\n",
    "The curse of dimensionality basically refers to the difficulties a machine learning algorithm faces\n",
    "when working with data in the higher dimensions, that did not exist in the lower dimensions.\n",
    "This happens because when you add dimensions (features), the minimum data requirements also increase rapidly.\n",
    "\n",
    "Curse of Dimensionality describes the explosive nature of increasing data dimensions and \n",
    "its resulting exponential increase in computational efforts required for its processing and/or analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688a0993-02ab-4b6b-a51b-9754f57fa5d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a9310d-3015-46e5-aaf6-630d17c2ddda",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. Can you explain the concept of feature selection and how it can help with dimensionality reduction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdde797f-0fba-44cd-8475-7f0bf3506b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature selection is simply selecting and excluding given features without changing them.\n",
    "Dimensionality reduction transforms features into a lower dimension.\n",
    "\n",
    "Feature Selection is the method of reducing the input variable to your model by using only \n",
    "relevant data and getting rid of noise in data.\n",
    "It is the process of automatically choosing relevant features for your machine learning model based on\n",
    "the type of problem you are trying to solve.\n",
    "\n",
    "Wrapper methods: Wrapper methods are a class of feature selection techniques that select subsets of \n",
    "features by evaluating the performance of a machine learning model. \n",
    "Unlike filter methods, wrapper methods use the model's performance on the training data as a criterion for selecting features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab278302-55ad-4e03-a6dd-298dd4c82ab8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e844887-83dc-4512-b7d1-a84a054d74fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. What are some limitations and drawbacks of using dimensionality reduction techniques in machine learning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ca6def-115e-4629-a39c-f7084f369c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "Disadvantages Of Dimensionality Reduction ----\n",
    "\n",
    "We lost some data during the dimensionality reduction process, which can impact how well future training algorithms work.\n",
    "It may need a lot of processing power.\n",
    "Interpreting transformed characteristics might be challenging.\n",
    "\n",
    "As the number of features increases, the number of samples also gets increased proportionally, \n",
    "and the chance of overfitting also increases. If the machine learning model is trained on high-dimensional data,\n",
    "it becomes overfitted and results in poor performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b937b8-f354-4a76-9ea4-b06a6ecc0ac7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f725ec9f-f6a0-4c03-aa2b-0d20ad875a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6. How does the curse of dimensionality relate to overfitting and underfitting in machine learning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ad76ef-3563-43be-8dbc-70a437833693",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN is very susceptible to overfitting due to the curse of dimensionality. Curse of dimensionality \n",
    "also describes the phenomenon where the feature space becomes \n",
    "increasingly sparse for an increasing number of dimensions of a fixed-size training dataset.\n",
    "\n",
    "\n",
    "Because of this inherent sparsity we end up overfitting, when we add more features to our data,\n",
    "which means we need more data to avoid sparsity — and that's the curse of dimensionality: as the number of features increase,\n",
    "our data become sparser, which results in overfitting, and we therefore need more data to avoid it\n",
    "\n",
    "The more predictors you have (the higher the dimensionality), the more likely it is that it will be\n",
    "possible to perfectly separate the two sets of values.\n",
    "As a result, overfitting becomes more of an issue when you have many predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaad2717-2c0d-4c78-9eec-f89d06cff2ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6f4639-1fa7-4ff2-a979-a91bcf7e6e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7. How can one determine the optimal number of dimensions to reduce data to when using\n",
    "dimensionality reduction techniques?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6be853c-d9e3-4d82-a7a1-b609399dab9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Principal Component Analysis is one of the leading linear techniques of dimensionality reduction. \n",
    "This method performs a direct mapping of the data to a lesser dimensional\n",
    "space in a way that maximizes the variance of the data in the low-dimensional representation.\n",
    "\n",
    "\n",
    "Dimensionality reduction refers to techniques for reducing the number of input variables in training data. \n",
    "When dealing with high dimensional data,\n",
    "it is often useful to reduce the dimensionality by projecting the data to a lower\n",
    "dimensional subspace which captures the “essence” of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af23f7ea-13c1-49be-bac9-d4eca8cb3df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "........................................The End.................................."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
